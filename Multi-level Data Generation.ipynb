{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Cancer in Gigapixel Medical Images\n",
    "## Applied Deep Learning (Spring 2018) \n",
    "### Akarsh Zingade, Kiran Ramesh, Arjun D'Cunha\n",
    "\n",
    "### YouTube [demo](https://www.youtube.com/watch?v=royB3p2m9pM). GitHub [repo](https://github.com/kira-95/adl_cancer_detection).\n",
    "\n",
    "Note: The 22 slides and tumor masks prepared by Prof. Joshua Gordon can be found [here](https://drive.google.com/drive/folders/1rwWL8zU9v0M27BtQKI52bF6bVLW82RL5?usp=sharing). The super set of this dataset can be found at [CAMELYON16](https://camelyon17.grand-challenge.org/Data/)\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "We base our approach on the the work by Google AI's [Lui et al. (2017)](https://arxiv.org/abs/1703.02442) in \"Detecting Cancer Metastases on Gigapixel Pathology Images\". We use ImageNet pretrained architecture and then use transfer learning to solve the problem of detecting cancer cells in the images. We train it using a sliding-window based approach, where we train the model using the patches extracted using the sliding windows. Once the model is trained, we create a heatmap of the prediction on medical slides that were not used during training.\n",
    "\n",
    "In this Notebook, we train the model using Focal Loss\n",
    "\n",
    "\n",
    "### Flow of the Notebook.\n",
    "\n",
    "1. Load the train and test slides.\n",
    "2. Extract patches for train and test slides.\n",
    "3. Split the train patches into train and validation set\n",
    "4. Save the train, validation and test slides.\n",
    "\n",
    "#### Train Slides: 031, 064, 075, 084, 091, 094, 096, 101\n",
    "#### Test Slides:  016, 078, 110\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the levels to be used for training the model.\n",
    "lvl1 = 4\n",
    "lvl2 = 5\n",
    "\n",
    "# Define the window size for the sliding window.\n",
    "window_size = 299\n",
    "\n",
    "# Define the center size to label the patch as tumorous or as healthy.\n",
    "patch_centre = 128\n",
    "\n",
    "# Number of Tumorous patches per slide per level\n",
    "tumor_sampled_limit = 100\n",
    "\n",
    "# Number of Healthy patches per slide per level\n",
    "healthy_sampled_limit = 100\n",
    "\n",
    "#Datafile Name prefix\n",
    "prefix = 'multilevel'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the relevant modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from openslide import open_slide, __library_version__ as openslide_version\n",
    "import os\n",
    "from PIL import Image\n",
    "from skimage.color import rgb2gray\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SLIDES_DIR = 'slides'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    \"\"\" Read a region from the slide\n",
    "    Return a numpy RBG array\n",
    "    \"\"\"\n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im\n",
    "  \n",
    "def find_tissue_pixels(image, intensity=0.8):\n",
    "    \"\"\" Return tissue pixels for an image\n",
    "    \"\"\"\n",
    "    im_gray = rgb2gray(image)\n",
    "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
    "    indices = np.where(im_gray <= intensity)\n",
    "    return zip(indices[0], indices[1])\n",
    "  \n",
    "def apply_mask(im, mask, color=(255,0,0)):\n",
    "    \"\"\" Return the mask as an image\n",
    "    \"\"\"\n",
    "    masked = np.copy(im)\n",
    "    for x,y in mask: masked[x][y] = color\n",
    "    return masked\n",
    "  \n",
    "def check_patch_centre(patch_mask, patch_centre):\n",
    "    \"\"\" Check if there is any tumor pixel in the 128x128 centre\n",
    "    inputs:\n",
    "    - patch_mask: array, tumor mask\n",
    "    - patch_centre: int, usually 128\n",
    "    outputs: Boolean\n",
    "    \"\"\"\n",
    "    patch_size = patch_mask.shape[0]\n",
    "    offset = int((patch_size-patch_centre)/2)\n",
    "    sum_cancers = np.sum(patc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(slide_path, tumor_mask_path, lvl1, lvl2, window_size, tumor_sampled_limit, healthy_sampled_limit):\n",
    "    \"\"\"\n",
    "    Return the patchs for two levels and their labels\n",
    "\n",
    "    slide_path: Path to the slide.\n",
    "    tumor_mask_path: Path to the tumor mask slide\n",
    "    lvl1 and lvl2: Levels of the slide\n",
    "    window_size: Sliding Window size\n",
    "    tumor_sampled_limit: Number of Tumorous patches to return per slide per level\n",
    "    healthy_sampled_limit: Number of Healthy patches to return per slide per level\n",
    "    \"\"\"\n",
    "        \n",
    "  patch_images_1 = []\n",
    "  patch_images_2 = []\n",
    "  \n",
    "  patch_labels = []\n",
    "  \n",
    "  num_cancer = 0\n",
    "  num_health = 0\n",
    " \n",
    "  reference_lvl = 4\n",
    "\n",
    "  slide = open_slide(slide_path)\n",
    "  print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, slide.level_dimensions[0][0], slide.level_dimensions[0][1]))\n",
    "\n",
    "  tumor_mask = open_slide(tumor_mask_path)\n",
    "  print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
    "  \n",
    "  slide_image = read_slide(slide, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=reference_lvl, \n",
    "                         width=slide.level_dimensions[reference_lvl][0], \n",
    "                         height=slide.level_dimensions[reference_lvl][1])\n",
    "  \n",
    "  tumor_mask_image = read_slide(tumor_mask, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=reference_lvl, \n",
    "                         width=slide.level_dimensions[reference_lvl][0], \n",
    "                         height=slide.level_dimensions[reference_lvl][1])\n",
    "  \n",
    "  tumor_mask_image = tumor_mask_image[:,:,0]\n",
    "  \n",
    "  #Get a list of tumor pixels at reference level\n",
    "  list_tumor_mask_pixels = np.nonzero(tumor_mask_image)\n",
    "  \n",
    "  #Construct a healthy tissue mask by subtracting tumor mask from tissue mask\n",
    "  tissue_pixels = find_tissue_pixels(slide_image)\n",
    "  tissue_regions = apply_mask(slide_image, tissue_pixels)\n",
    "\n",
    "  healthy_mask_image = tissue_regions[:,:,0] - tumor_mask_image\n",
    "  healthy_mask_image = healthy_mask_image > 0\n",
    "  healthy_mask_image = healthy_mask_image.astype('int')\n",
    "\n",
    "  #Get a list of healthy tissue pixels at reference level\n",
    "  list_healthy_mask_pixels = np.nonzero(healthy_mask_image)\n",
    "  \n",
    "  #Collect tumor patches\n",
    "  tumor_pixels = random.sample(list(zip(list_tumor_mask_pixels[1], list_tumor_mask_pixels[0])), tumor_sampled_limit * 10)\n",
    "  \n",
    "  count = 0\n",
    "  for pixel in tumor_pixels:\n",
    "    if count >= tumor_sampled_limit:\n",
    "      break\n",
    "      \n",
    "    (x_ref, y_ref) = pixel\n",
    "\n",
    "    #Convert reference_lvl coordinates to level 0 coordinates\n",
    "    x0 = x_ref*(2**reference_lvl)\n",
    "    y0 = y_ref*(2**reference_lvl)\n",
    "    \n",
    "    downsample_factor = 2**lvl1\n",
    "    \n",
    "    patch = read_slide(slide,\n",
    "                       x = x0-(window_size//2)*downsample_factor,\n",
    "                       y = y0-(window_size//2)*downsample_factor, \n",
    "                       level = lvl1,\n",
    "                       width = window_size,\n",
    "                       height = window_size)\n",
    "    \n",
    "    tumor_mask_patch = read_slide(tumor_mask,\n",
    "                       x = x0-(window_size//2)*downsample_factor,\n",
    "                       y = y0-(window_size//2)*downsample_factor, \n",
    "                       level = lvl1,\n",
    "                       width = window_size,\n",
    "                       height = window_size)\n",
    "    \n",
    "    tumor_mask_patch = tumor_mask_patch[:,:,0]\n",
    "    \n",
    "    tissue_pixels = find_tissue_pixels(patch)\n",
    "    tissue_pixels = list(tissue_pixels)\n",
    "    percent_tissue = len(tissue_pixels) / float(patch.shape[0] * patch.shape[0]) * 100\n",
    "\n",
    "    if percent_tissue > 50 and check_patch_centre(tumor_mask_patch, 128):\n",
    "        patch_images_1.append(patch)\n",
    "        patch_images_2.append(read_slide(slide, x = x0-(window_size//2)*downsample_factor, y = y0-(window_size//2)*downsample_factor, level = lvl2, width = window_size, height = window_size))\n",
    "\n",
    "        patch_labels.append(1)\n",
    "        count += 1\n",
    "        \n",
    "\n",
    "        \n",
    "  #Collect healthy patches\n",
    "  healthy_pixels = random.sample(list(zip(list_healthy_mask_pixels[1], list_healthy_mask_pixels[0])), healthy_sampled_limit * 20)\n",
    "  \n",
    "  count = 0\n",
    "  for pixel in healthy_pixels:\n",
    "    if count >= healthy_sampled_limit:\n",
    "      break\n",
    "      \n",
    "    (x_ref, y_ref) = pixel\n",
    "\n",
    "    #Convert reference_lvl coordinates to level 0 coordinates\n",
    "    x0 = x_ref*(2**reference_lvl)\n",
    "    y0 = y_ref*(2**reference_lvl)\n",
    "    \n",
    "    downsample_factor = 2**lvl1\n",
    "    \n",
    "    patch = read_slide(slide,\n",
    "                       x = x0-(window_size//2)*downsample_factor,\n",
    "                       y = y0-(window_size//2)*downsample_factor, \n",
    "                       level = lvl1,\n",
    "                       width = window_size,\n",
    "                       height = window_size)\n",
    "    \n",
    "    tumor_mask_patch = read_slide(tumor_mask,\n",
    "                       x = x0-(window_size//2)*downsample_factor,\n",
    "                       y = y0-(window_size//2)*downsample_factor, \n",
    "                       level = lvl1,\n",
    "                       width = window_size,\n",
    "                       height = window_size)\n",
    "    \n",
    "    tumor_mask_patch = tumor_mask_patch[:,:,0]\n",
    "    \n",
    "    tissue_pixels = find_tissue_pixels(patch)\n",
    "    tissue_pixels = list(tissue_pixels)\n",
    "    percent_tissue = len(tissue_pixels) / float(patch.shape[0] * patch.shape[0]) * 100\n",
    "\n",
    "    if percent_tissue > 50 and (not check_patch_centre(tumor_mask_patch, 128)):\n",
    "        patch_images_1.append(patch)\n",
    "        patch_images_2.append(read_slide(slide, x = x0-(window_size//2)*downsample_factor, y = y0-(window_size//2)*downsample_factor, level = lvl2, width = window_size, height = window_size))\n",
    "        patch_labels.append(0)\n",
    "        count += 1\n",
    "\n",
    "  return patch_images_1, patch_images_2, patch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract patches for train slides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainval_patch_images_lev1 = []\n",
    "trainval_patch_images_lev2 = []\n",
    "trainval_patch_labels = []\n",
    "\n",
    "TRAIN_SLIDE_NUMS = ['016', '031', '064', '075', '078', '084', '094', '096', '101']\n",
    "\n",
    "for num in TRAIN_SLIDE_NUMS:\n",
    "  slide_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '.tif')\n",
    "  tumor_mask_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '_mask.tif')  \n",
    "  patch_images_1, patch_images_2, patch_labels = generate_images(slide_path, tumor_mask_path, lvl1, lvl2, window_size, tumor_sampled_limit, healthy_sampled_limit)\n",
    "  trainval_patch_images_lev1.extend(patch_images_1)\n",
    "  trainval_patch_images_lev2.extend(patch_images_2)\n",
    "  trainval_patch_labels.extend(patch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract patches for test slides."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_patch_images_lev1 = []\n",
    "test_patch_images_lev2 = []\n",
    "test_patch_labels = []\n",
    "\n",
    "TEST_SLIDE_NUMS = ['016','078','110']\n",
    "\n",
    "for num in TEST_SLIDE_NUMS:\n",
    "  slide_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '.tif')\n",
    "  tumor_mask_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '_mask.tif')  \n",
    "  patch_images_1, patch_images_2, patch_labels = generate_images(slide_path, tumor_mask_path, lvl1, lvl2, window_size, tumor_sampled_limit, healthy_sampled_limit)\n",
    "  test_patch_images_lev1.extend(patch_images_1)\n",
    "  test_patch_images_lev2.extend(patch_images_2)\n",
    "  test_patch_labels.extend(patch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1_trainval = np.asarray(trainval_patch_images_lev1)\n",
    "X2_trainval = np.asarray(trainval_patch_images_lev2)\n",
    "y_trainval = np.asarray(trainval_patch_labels)\n",
    "\n",
    "X1_test = np.asarray(test_patch_images_lev1)\n",
    "X2_test = np.asarray(test_patch_images_lev2)\n",
    "y_test = np.asarray(test_patch_labels)\n",
    "\n",
    "print(X1_trainval.shape, X2_trainval.shape, len(y_trainval), X1_test.shape, X2_test.shape, len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del trainval_patch_images_lev1, trainval_patch_images_lev2, trainval_patch_labels,\n",
    "del test_patch_images_lev1, test_patch_images_lev2, test_patch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = list(range(len(X1_trainval)))\n",
    "np.random.shuffle(idxs)\n",
    "train_idxs = idxs[:int(0.8*len(idxs))]\n",
    "val_idxs = idxs[int(0.8*len(idxs)):]\n",
    "\n",
    "X1_train = X1_trainval[train_idxs]\n",
    "X2_train = X2_trainval[train_idxs]\n",
    "y_train = y_trainval[train_idxs]\n",
    "\n",
    "X1_val = X1_trainval[val_idxs]\n",
    "X2_val = X2_trainval[val_idxs]\n",
    "y_val = y_trainval[val_idxs]\n",
    "\n",
    "dataset = {\n",
    "    'X1_train' : X1_train,\n",
    "    'X2_train' : X2_train,\n",
    "    'y_train' : y_train,\n",
    "    'X1_val' : X1_val,\n",
    "    'X2_val' : X2_val,\n",
    "    'y_val' : y_val,\n",
    "    'X1_test' : X1_test,\n",
    "    'X2_test' : X2_test,\n",
    "    'y_test' : y_test,\n",
    "}\n",
    "\n",
    "np.save('./custom_multilevel_levels_' + str(lev1) + '_' + str(lev2), dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
