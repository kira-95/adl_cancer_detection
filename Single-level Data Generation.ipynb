{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detecting Cancer in Gigapixel Medical Images\n",
    "## Applied Deep Learning (Spring 2018) \n",
    "### Akarsh Zingade, Kiran Ramesh, Arjun D'Cunha\n",
    "\n",
    "### YouTube [demo](https://www.youtube.com/watch?v=royB3p2m9pM). GitHub [repo](https://github.com/kira-95/adl_cancer_detection).\n",
    "\n",
    "Note: The 22 slides and tumor masks prepared by Prof. Joshua Gordon can be found [here](https://drive.google.com/drive/folders/1rwWL8zU9v0M27BtQKI52bF6bVLW82RL5?usp=sharing). The super set of this dataset can be found at [CAMELYON16](https://camelyon17.grand-challenge.org/Data/)\n",
    "\n",
    "\n",
    "### Summary\n",
    "\n",
    "We base our approach on the the work by Google AI's [Lui et al. (2017)](https://arxiv.org/abs/1703.02442) in \"Detecting Cancer Metastases on Gigapixel Pathology Images\". We use ImageNet pretrained architecture and then use transfer learning to solve the problem of detecting cancer cells in the images. We train it using a sliding-window based approach, where we train the model using the patches extracted using the sliding windows. Once the model is trained, we create a heatmap of the prediction on medical slides that were not used during training.\n",
    "\n",
    "\n",
    "### Flow of the Notebook.\n",
    "\n",
    "1. Load the train and test slides.\n",
    "2. Extract patches for train and test slides.\n",
    "3. Split the train patches into train and validation set\n",
    "4. Save the train, validation and test slides.\n",
    "\n",
    "\n",
    "#### Train Slides: 031, 064, 075, 084, 091, 094, 096, 101\n",
    "#### Test Slides:  016, 078, 110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# try:\n",
    "#   drive.mount('/content/gdrive')\n",
    "# except: \n",
    "#   print (\"already mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zcBl9Qc7VR1b"
   },
   "outputs": [],
   "source": [
    "# Define the level to be used for training the model.\n",
    "lev = 4\n",
    "\n",
    "# Define the window size for the sliding window.\n",
    "patch_size = 299\n",
    "\n",
    "# Define the center size to label the patch as tumorous or as healthy.\n",
    "patch_centre = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7107,
     "status": "ok",
     "timestamp": 1557950800569,
     "user": {
      "displayName": "Akarsh Umesh Zingade",
      "photoUrl": "",
      "userId": "11959994497769429797"
     },
     "user_tz": 240
    },
    "id": "u1ncaxi5VYU7",
    "outputId": "8d2e972f-e81c-4ff3-eee3-4a2f00f64967"
   },
   "outputs": [],
   "source": [
    "# # Install the OpenSlide C library and Python bindings\n",
    "# !apt-get install openslide-tools\n",
    "# !pip install openslide-python\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the relevant modules. \n",
    "#### Import the Garbage Collection module to free objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A1oEY7uzVab0"
   },
   "outputs": [],
   "source": [
    "from openslide import open_slide, __library_version__ as openslide_lib_version, __version__ as openslide_version\n",
    "\n",
    "import numpy as np\n",
    "import random, os, glob, time\n",
    "from skimage.color import rgb2gray\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p2MjeJ9ZVmz3"
   },
   "outputs": [],
   "source": [
    "\n",
    "def read_slide(slide, x, y, level, width, height, as_float=False):\n",
    "    \"\"\" Read a region from the slide\n",
    "    Return a numpy RBG array\n",
    "    \"\"\"\n",
    "    \n",
    "    im = slide.read_region((x,y), level, (width, height))\n",
    "    im = im.convert('RGB') # drop the alpha channel\n",
    "    if as_float:\n",
    "        im = np.asarray(im, dtype=np.float32)\n",
    "    else:\n",
    "        im = np.asarray(im)\n",
    "    assert im.shape == (height, width, 3)\n",
    "    return im\n",
    "\n",
    "def find_tissue_pixels(image, intensity=0.8):\n",
    "    \"\"\" Return tissue pixels for an image\n",
    "    \"\"\"\n",
    "    \n",
    "    im_gray = rgb2gray(image)\n",
    "    assert im_gray.shape == (image.shape[0], image.shape[1])\n",
    "    indices = np.where(im_gray <= intensity)\n",
    "    return zip(indices[0], indices[1])\n",
    "  \n",
    "def apply_mask(im, mask, color=(1,0,0)):\n",
    "    \"\"\" Return the mask as an image\n",
    "    \"\"\"\n",
    "    \n",
    "    masked = np.zeros(im.shape)\n",
    "    for x,y in mask: masked[x][y] = color\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQOVe1GvWlAL"
   },
   "outputs": [],
   "source": [
    "def get_patches(slide, tumor_mask, lev, x0, y0, patch_size):\n",
    "    \"\"\"\n",
    "    Return the patch of given size for a given coordinate\n",
    "    \n",
    "    slide: Input slide\n",
    "    tumor_mask: Input mask for the slide\n",
    "    lev: Level of the slide\n",
    "    x0: x-coordinate value for the patch\n",
    "    y0: y-coordinate value for the patch\n",
    "    \"\"\"\n",
    "    # read RGB patch\n",
    "    patch_image = read_slide(slide,\n",
    "                             x = x0-(patch_size//2)*(2**lev),\n",
    "                             y = y0-(patch_size//2)*(2**lev), \n",
    "                             level = lev,\n",
    "                             width = patch_size,\n",
    "                             height = patch_size)\n",
    "    \n",
    "    # read tumor mask\n",
    "    patch_mask = read_slide(tumor_mask,\n",
    "                            x = x0-(patch_size//2)*(2**lev),\n",
    "                            y = y0-(patch_size//2)*(2**lev), \n",
    "                            level = lev,\n",
    "                            width = patch_size,\n",
    "                            height = patch_size)\n",
    "    \n",
    "    patch_mask = patch_mask[:,:,0]\n",
    "    \n",
    "    # make tissue mask\n",
    "    tissue_pixels = find_tissue_pixels(patch_image)\n",
    "    patch_tissue = apply_mask(patch_image, tissue_pixels)\n",
    "    \n",
    "    return patch_image, patch_mask, patch_tissue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7--UZGj3XYQA"
   },
   "outputs": [],
   "source": [
    "def check_patch_centre(patch_mask, patch_centre):\n",
    "    \"\"\"\n",
    "    Check if there are any tumour in the patch.\n",
    "    patch_mask: Mask of the patch\n",
    "    patch_centre: Center window to observe the patch.\n",
    "    \"\"\"\n",
    "    offset = int((patch_mask.shape[0]-patch_centre)/2)\n",
    "    \n",
    "    sum_ = np.sum(patch_mask[offset:offset+patch_centre, offset:offset+patch_centre])\n",
    "    \n",
    "    return sum_>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_uORBBZlXt_j"
   },
   "outputs": [],
   "source": [
    "def generate_images(slide_path, tumor_mask_path, lvl, window_size, num_pos_imgs, num_neg_imgs):\n",
    "  \"\"\"\n",
    "  Generate the patches for the training and test slides\n",
    "  \n",
    "  slide_path: Path to the slide.\n",
    "  lvl: The level at which the predictions are being evaluated\n",
    "  tumor_mask_path: Path to the tumor mask slide\n",
    "  window_size: Sliding Window size\n",
    "  num_pos_imgs: Number of Tumorous patches to return\n",
    "  num_neg_imgs: Number of healthy patches to return\n",
    "  \n",
    "  \"\"\"\n",
    "  patch_images = []\n",
    "  patch_labels = []\n",
    "  \n",
    "  stride = 80\n",
    " \n",
    "  slide = open_slide(slide_path)\n",
    "  print (\"Read WSI from %s with width: %d, height: %d\" % (slide_path, slide.level_dimensions[0][0], slide.level_dimensions[0][1]))\n",
    "\n",
    "  tumor_mask = open_slide(tumor_mask_path)\n",
    "  print (\"Read tumor mask from %s\" % (tumor_mask_path))\n",
    "  \n",
    "  slide_image = read_slide(slide, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=lvl, \n",
    "                         width=slide.level_dimensions[lvl][0], \n",
    "                         height=slide.level_dimensions[lvl][1])\n",
    "  \n",
    "  tumor_mask_image = read_slide(tumor_mask, \n",
    "                         x=0, \n",
    "                         y=0, \n",
    "                         level=lvl, \n",
    "                         width=slide.level_dimensions[lvl][0], \n",
    "                         height=slide.level_dimensions[lvl][1])\n",
    "  \n",
    "  tumor_mask_image = tumor_mask_image[:,:,0]\n",
    "  \n",
    "  count = 0\n",
    "  \n",
    "  for i in range(0, slide.level_dimensions[lvl][1] - window_size - stride, stride):\n",
    "    for j in range(0, slide.level_dimensions[lvl][0] - window_size - stride, stride):\n",
    "      \n",
    "      patch = slide_image[i:i+window_size, j:j+window_size]\n",
    "      tumor_mask_patch = tumor_mask_image[i:i+window_size, j:j+window_size]\n",
    "      \n",
    "      \n",
    "      \n",
    "      tissue_pixels = find_tissue_pixels(patch)\n",
    "      tissue_pixels = list(tissue_pixels)\n",
    "      percent_tissue = len(tissue_pixels) / float(patch.shape[0] * patch.shape[0]) * 100\n",
    "    \n",
    "      if check_patch_centre(tumor_mask_patch, 128) and percent_tissue > 50:\n",
    "        patch_images.append(patch)\n",
    "        patch_labels.append(1)\n",
    "        continue\n",
    "        \n",
    "      if percent_tissue > 50:\n",
    "        patch_images.append(patch)\n",
    "        patch_labels.append(0)\n",
    "      else:\n",
    "        if np.random.uniform() > 0.9:\n",
    "          patch_images.append(patch)\n",
    "          patch_labels.append(0)\n",
    "        \n",
    "      count += 1\n",
    "      if count % 2000 == 0:\n",
    "        print(count)\n",
    "   \n",
    "  tumor_idxs = [idx for idx in range(len(patch_labels)) if int(patch_labels[idx]) == 1]\n",
    "  normal_idxs = [idx for idx in range(len(patch_labels)) if int(patch_labels[idx]) == 0]\n",
    "  np.random.shuffle(tumor_idxs)\n",
    "  np.random.shuffle(normal_idxs)\n",
    "  tumor_idxs = tumor_idxs[:num_pos_imgs]\n",
    "  normal_idxs = normal_idxs[:num_neg_imgs]\n",
    "  idxs = tumor_idxs + normal_idxs\n",
    "  np.random.shuffle(idxs)\n",
    "  patch_images = [patch_images[idx] for idx in idxs]\n",
    "  patch_labels = [patch_labels[idx] for idx in idxs]\n",
    "        \n",
    "  return patch_images, patch_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract patches for train slides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 907
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 473151,
     "status": "ok",
     "timestamp": 1557951266690,
     "user": {
      "displayName": "Akarsh Umesh Zingade",
      "photoUrl": "",
      "userId": "11959994497769429797"
     },
     "user_tz": 240
    },
    "id": "Q47c1enBidVe",
    "outputId": "ece759a3-4682-4929-86f2-9786996c1091"
   },
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "TRAIN_SLIDES = ['016', '031', '064', '075', '084','091', '096', '101']\n",
    "SLIDES_DIR = './slides/'\n",
    "\n",
    "for num in TRAIN_SLIDES:\n",
    "  print (num)\n",
    "  slide_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '.tif')\n",
    "  tumor_mask_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '_mask.tif')  \n",
    "  patch_images, patch_labels = generate_images(slide_path, tumor_mask_path, 4, 299, 400,100)\n",
    "  X.extend(patch_images)\n",
    "  y.extend(patch_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract patches for test slides. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 592692,
     "status": "ok",
     "timestamp": 1557951386242,
     "user": {
      "displayName": "Akarsh Umesh Zingade",
      "photoUrl": "",
      "userId": "11959994497769429797"
     },
     "user_tz": 240
    },
    "id": "qGKBBCofkGwB",
    "outputId": "70641332-db26-43a6-9422-83f29918f6c0"
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "TEST_SLIDES = ['078','016','110']#['091','110']\n",
    "SLIDES_DIR = './slides/'\n",
    "\n",
    "for num in TEST_SLIDES:\n",
    "  print (num)\n",
    "  slide_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '.tif')\n",
    "  tumor_mask_path = os.path.join(SLIDES_DIR, 'tumor_' + num + '_mask.tif')  \n",
    "  patch_images, patch_labels = generate_images(slide_path, tumor_mask_path, 4, 299, 400,100)\n",
    "  X_test.extend(patch_images)\n",
    "  y_test.extend(patch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qCMFytZXnaIk"
   },
   "outputs": [],
   "source": [
    "# Split the train set into train and validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "del X,y\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the count of images for each class across train, val and test dataset\n",
    "\n",
    "try:\n",
    "  unique, counts = np.unique(np.argmax(y_train,axis=1), return_counts=True)\n",
    "except:\n",
    "  unique, counts = np.unique(y_train, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "try:\n",
    "  unique, counts = np.unique(np.argmax(y_val,axis=1), return_counts=True)\n",
    "except:\n",
    "  unique, counts = np.unique(y_val, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n",
    "\n",
    "try:\n",
    "  unique, counts = np.unique(np.argmax(y_test,axis=1), return_counts=True)\n",
    "except:\n",
    "  unique, counts = np.unique(y_test, return_counts=True)\n",
    "print (dict(zip(unique, counts)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the Train, Validation and Test Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_ubo1FL6nVas"
   },
   "outputs": [],
   "source": [
    "dataset = {\n",
    "    'X_train' : X_train,\n",
    "    'y_train' : y_train,\n",
    "    'X_val' : X_val,\n",
    "    'y_val' : y_val,\n",
    "    'X_test' : X_test,\n",
    "    'y_test' : y_test,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NMM7MaXUnqw_"
   },
   "outputs": [],
   "source": [
    "np.save('./dataset_final',dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ycTwnhgDn-Iy"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "akarsh extract",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
